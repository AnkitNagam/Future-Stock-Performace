{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Grid Search CV - Neural Network.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOz7578s+NoTneYpvDnA+LU"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "02Kz2DmJc9W6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "313b860b-5ce6-4a44-9882-376a1f3e6706"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Et40Dsq2M_R5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "fe56db05-b718-4d37-c8bb-b5f426e0d224"
      },
      "source": [
        "!apt install operator"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "E: Unable to locate package operator\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MChb0fwjBRf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "837e1e12-2917-45e3-ce43-3e88e42af1a2"
      },
      "source": [
        "#############################################################################\n",
        "#\n",
        "# Wrapper Feat Select Helper\n",
        "#\n",
        "##########################################\n",
        "\n",
        "#Recursive Function for searching thru feature space\n",
        "def feat_space_search(arr, curr_idx):\n",
        "    '''Setup currently as exhuastive search, but could be changed to use\n",
        "       greedy search, random search, genetic algorithms, etc. ... also\n",
        "       no regularization, so probably selects more features than necessary'''\n",
        "    global roll_idx, combo_ctr, best_score, sel_idx\n",
        "    \n",
        "    if curr_idx==feat_cnt:\n",
        "        #If end of feature array, roll thru combinations\n",
        "        roll_idx=roll_idx+1\n",
        "        print (\"Combos Searched so far:\", combo_ctr, \"Current Best Score:\", best_score)\n",
        "        for i in range(roll_idx, len(arr)):\n",
        "            arr[i]=0\n",
        "        if roll_idx<feat_cnt-1:\n",
        "            feat_space_search(arr, roll_idx+1)                                                                      #Recurse till end of rolls\n",
        "        \n",
        "    else:\n",
        "        #Else setup next feature combination and calc performance\n",
        "        arr[curr_idx]=1\n",
        "        data=data_np#_wrap                                                                                          #Temp array to hold data\n",
        "        temp_del=[i for i in range(len(arr)) if arr[i]==0]                                                          #Pick out features not in this combo, and remove\n",
        "        data = np.delete(data, temp_del, axis=1)\n",
        "        data_train, data_test, target_train, target_test = train_test_split(data, target_np, test_size=0.35)                \n",
        "\n",
        "        if binning==1:\n",
        "            if bin_cnt<=2:\n",
        "                scorers = {'Accuracy': 'accuracy', 'roc_auc': 'roc_auc'}\n",
        "                scores = cross_validate(clf, data_np, target_np, scoring=scorers, cv=5) \n",
        "                score = scores['test_roc_auc'].mean()                                                               #AUC\n",
        "            else:\n",
        "                scorers = {'Accuracy': 'accuracy'}\n",
        "                scores = cross_validate(clf, data_np, target_np, scoring=scorers, cv=5) \n",
        "                score = scores['test_Accuracy'].mean()                                                              #Accuracy\n",
        "            print('Random Forest Acc/AUC:', curr_idx, feat_arr, len(data[0]), score)\n",
        "            if score>best_score:                                                                                    #Compare performance and update sel_idx and best_score, if needed\n",
        "                best_score=score\n",
        "                sel_idx=copy.deepcopy(arr) \n",
        "                \n",
        "        if binning==0:\n",
        "            scorers = {'Neg_MSE': 'neg_mean_squared_error', 'expl_var': 'explained_variance'}\n",
        "            scores = cross_validate(rgr, data, target_np, scoring=scorers, cv=5)    \n",
        "            score = np.asarray([math.sqrt(-x) for x in scores['test_Neg_MSE']]).mean()                              #RMSE\n",
        "            print('Random Forest RMSE:', curr_idx, feat_arr, len(data[0]), score)\n",
        "            if score<best_score:                                                                                    #Compare performance and update sel_idx and best_score, if needed\n",
        "                best_score=score\n",
        "                sel_idx=copy.deepcopy(arr) \n",
        "\n",
        "        #move to next feature index and recurse\n",
        "        combo_ctr+=1  \n",
        "        curr_idx+=1\n",
        "        feat_space_search(arr, curr_idx)                                                                            #Recurse till end of iteration for roll\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement itemgetters (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for itemgetters\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q71AyFlnc-ZW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "28048704-c051-492f-fa2d-f1774c5cf37c"
      },
      "source": [
        "#SciKit DSC540 HW1\n",
        "'''created by Casey Bennett 2018, www.CaseyBennett.com'''\n",
        "\n",
        "import sys\n",
        "import csv\n",
        "import math\n",
        "import numpy as np\n",
        "#from operator import itemgetters \n",
        "import time\n",
        "import copy\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.externals import joblib\n",
        "from sklearn.feature_selection import RFE, VarianceThreshold, SelectFromModel\n",
        "from sklearn.feature_selection import SelectKBest, mutual_info_regression, mutual_info_classif, chi2\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import cross_validate, train_test_split\n",
        "from sklearn.preprocessing import KBinsDiscretizer, scale\n",
        "\n",
        "#Handle annoying warnings\n",
        "import warnings, sklearn.exceptions\n",
        "warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.ConvergenceWarning)\n",
        "\n",
        "\n",
        "\n",
        "#############################################################################\n",
        "#\n",
        "# Global parameters\n",
        "#\n",
        "#####################\n",
        "\n",
        "target_idx=199                                        #Index of Target variable\n",
        "cross_val=1                                         #Control Switch for CV\n",
        "norm_target=0                                       #Normalize target switch\n",
        "norm_features=0                                     #Normalize target switch\n",
        "binning=1                                           #Control Switch for Bin Target\n",
        "bin_cnt=2                                           #If bin target, this sets number of classes\n",
        "feat_select=1                                       #Control Switch for Feature Selection\n",
        "fs_type=2                                           #Feature Selection type (1=Stepwise Backwards Removal, 2=Wrapper Select, 3=Univariate Selection)\n",
        "lv_filter=0                                         #Control switch for low variance filter on features\n",
        "feat_start=0                                       #Start column of features\n",
        "k_cnt=5                                             #Number of 'Top k' best ranked features to select, only applies for fs_types 1 and 3\n",
        "\n",
        "#Set global model parameters\n",
        "rand_st=0                                           #Set Random State variable for randomizing splits on runs\n",
        "\n",
        "\n",
        "#############################################################################\n",
        "#\n",
        "# Load Data\n",
        "#\n",
        "#####################\n",
        "\n",
        "file1= csv.reader(open('/content/drive/My Drive/Programming machine Learning/cleaned.csv'), delimiter=',', quotechar='\"')\n",
        "\n",
        "#Read Header Line\n",
        "header=next(file1)            \n",
        "\n",
        "#Read data\n",
        "data=[]\n",
        "target=[]\n",
        "for row in file1:\n",
        "    #Load Target\n",
        "    if row[target_idx]=='':                         #If target is blank, skip row                       \n",
        "        continue\n",
        "    else:\n",
        "        target.append((row[target_idx]))       #If pre-binned class, change float to int\n",
        "\n",
        "    #Load row into temp array, cast columns  \n",
        "    temp=[]\n",
        "                 \n",
        "    for j in range(feat_start,len(header)-2):\n",
        "        if row[j]=='':\n",
        "            temp.append(float())\n",
        "        else:\n",
        "            temp.append((row[j]))\n",
        "\n",
        "    #Load temp into Data array\n",
        "    data.append(temp)\n",
        "  \n",
        "#Test Print\n",
        "# =============================================================================\n",
        "# header[0]\n",
        "# print(header)\n",
        "# print(len(target),len(data))\n",
        "# for i in range(10):\n",
        "#     print(target[i])\n",
        "#     print(data[i])\n",
        "# print('\\n')\n",
        "# \n",
        "# =============================================================================\n",
        "data_np=np.asarray(data)\n",
        "target_np=np.asarray(target)\n",
        "\n",
        "data_np.astype(np.float64)\n",
        "target_np.astype(np.float64)\n",
        "\n",
        "\n",
        "\n",
        "#############################################################################\n",
        "#\n",
        "# Preprocess data\n",
        "#\n",
        "##########################################\n",
        "\n",
        "if norm_target==1:\n",
        "    #Target normalization for continuous values\n",
        "    target_np=scale(target_np)\n",
        "\n",
        "if norm_features==1:\n",
        "    #Feature normalization for continuous values\n",
        "    data_np=scale(data_np)\n",
        "\n",
        "'''if binning==1:\n",
        "    #Discretize Target variable with KBinsDiscretizer\n",
        "    enc = KBinsDiscretizer(n_bins=[bin_cnt], encode='ordinal', strategy='quantile')                         #Strategy here is important, quantile creating equal bins, but kmeans prob being more valid \"clusters\"\n",
        "    target_np_bin = enc.fit_transform(target_np.reshape(-1,1))\n",
        "\n",
        "    #Get Bin min/max\n",
        "    temp=[[] for x in range(bin_cnt+1)]\n",
        "    for i in range(len(target_np)):\n",
        "        for j in range(bin_cnt):\n",
        "            if target_np_bin[i]==j:\n",
        "                temp[j].append(target_np[i])\n",
        "\n",
        "    for j in range(bin_cnt):\n",
        "        print('Bin', j, ':', min(temp[j]), max(temp[j]), len(temp[j]))\n",
        "    print('\\n')\n",
        "\n",
        "    #Convert Target array back to correct shape\n",
        "    target_np=np.ravel(target_np_bin)'''\n",
        "\n",
        "\n",
        "#############################################################################\n",
        "#\n",
        "# Feature Selection\n",
        "#\n",
        "##########################################\n",
        "\n",
        "#Low Variance Filter\n",
        "if lv_filter==1:\n",
        "    print('--LOW VARIANCE FILTER ON--', '\\n')\n",
        "    \n",
        "    #LV Threshold\n",
        "    sel = VarianceThreshold(threshold=0.5)                                      #Removes any feature with less than 20% variance\n",
        "    fit_mod=sel.fit(data_np)\n",
        "    fitted=sel.transform(data_np)\n",
        "    sel_idx=fit_mod.get_support()\n",
        "\n",
        "    #Get lists of selected and non-selected features (names and indexes)\n",
        "    temp=[]\n",
        "    temp_idx=[]\n",
        "    temp_del=[]\n",
        "    for i in range(len(data_np[0])):\n",
        "        if sel_idx[i]==1:                                                           #Selected Features get added to temp header\n",
        "            temp.append(header[i+feat_start])\n",
        "            temp_idx.append(i)\n",
        "        else:                                                                       #Indexes of non-selected features get added to delete array\n",
        "            temp_del.append(i)\n",
        "\n",
        "    print('Selected', temp)\n",
        "    print('Features (total, selected):', len(data_np[0]), len(temp))\n",
        "    print('\\n')\n",
        "\n",
        "    #Filter selected columns from original dataset\n",
        "    header = header[0:feat_start]\n",
        "    for field in temp:\n",
        "        header.append(field)\n",
        "    data_np = np.delete(data_np, temp_del, axis=1)                                 #Deletes non-selected features by index\n",
        "\n",
        "\n",
        "#Feature Selection\n",
        "if feat_select==1:\n",
        "    '''Three steps:\n",
        "       1) Run Feature Selection\n",
        "       2) Get lists of selected and non-selected features\n",
        "       3) Filter columns from original dataset\n",
        "       '''\n",
        "    \n",
        "    print('--FEATURE SELECTION ON--', '\\n')\n",
        "    \n",
        "    ##1) Run Feature Selection #######\n",
        "    if fs_type==1:\n",
        "        #Stepwise Recursive Backwards Feature removal\n",
        "        if binning==1:\n",
        "            clf = RandomForestClassifier(n_estimators=200, max_depth=None, min_samples_split=3, criterion='entropy', random_state=rand_st)\n",
        "            sel = RFE(clf, n_features_to_select=k_cnt, step=.1)\n",
        "            print('Stepwise Recursive Backwards - Random Forest: ')\n",
        "        if binning==0:\n",
        "            rgr = RandomForestRegressor(n_estimators=500, max_depth=None, min_samples_split=3, criterion='mse', random_state=rand_st)\n",
        "            sel = RFE(rgr, n_features_to_select=k_cnt, step=.1)\n",
        "            print('Stepwise Recursive Backwards - Random Forest: ')\n",
        "            \n",
        "        fit_mod=sel.fit(data_np, target_np)\n",
        "        print(sel.ranking_)\n",
        "        sel_idx=fit_mod.get_support()      \n",
        "\n",
        "    if fs_type==2:\n",
        "        #Wrapper Select via model\n",
        "        if binning==1:\n",
        "            clf=GradientBoostingClassifier(loss = \"deviance\",n_estimators=100,learning_rate=0.1,max_depth=3,min_samples_split=3,random_state = rand_st)\n",
        "            sel = SelectFromModel(clf, prefit=False, threshold='mean', max_features=None)                                                           #to select only based on max_features, set to integer value and set threshold=-np.inf\n",
        "            print ('Wrapper Select: ')\n",
        "        if binning==0:\n",
        "            rgr = '''Unused in this homework'''\n",
        "            sel = SelectFromModel(rgr, prefit=False, threshold='mean', max_features=None)\n",
        "            print ('Wrapper Select: ')\n",
        "            \n",
        "        fit_mod=sel.fit(data_np, target_np)    \n",
        "        sel_idx=fit_mod.get_support()\n",
        "\n",
        "    if fs_type==3:\n",
        "        if binning==1:                                                              ######Only work if the Target is continuous###########\n",
        "            #Univariate Feature Selection - Mutual Info classif\n",
        "            sel=SelectKBest(mutual_info_classif)\n",
        "            fit_mod=sel.fit(data_np, target_np)\n",
        "            print ('Univariate Feature Selection - Mutual Info: ')\n",
        "            sel_idx=fit_mod.get_support()\n",
        "\n",
        "        #Print ranked variables out sorted\n",
        "        temp=[]\n",
        "        scores=fit_mod.scores_\n",
        "        for i in range(feat_start, len(header)-2):            \n",
        "            temp.append([header[i], float(scores[i-feat_start])])\n",
        "\n",
        "        print('Ranked Features')\n",
        "        temp_sort=sorted(temp, key=itemgetter(1), reverse=True)\n",
        "        for i in range(len(temp_sort)):\n",
        "            print(i, temp_sort[i][0], ':', temp_sort[i][1])\n",
        "        print('\\n')         \n",
        "    \n",
        "    if fs_type==4:\n",
        "        print(\"feature importance\")\n",
        "        clf= RandomForestClassifier(n_estimators = 100,max_depth = None,min_samples_split = 10,criterion = 'entropy',random_state = rand_st)              \n",
        "        clf.fit(data_np,target_np)\n",
        "        sel_idx = []\n",
        "        for x in clf.feature_importances_:\n",
        "            if x >= np.mean(clf.feature_importances_):\n",
        "                sel_idx.append(1)\n",
        "            else:\n",
        "                sel_idx.append(0)\n",
        "                \n",
        "\n",
        "    if fs_type ==5:\n",
        "      print(\"L2 Regularization\")\n",
        "      sel = SelectFromModel(LogisticRegression(penalty = 'l2', C = 1.0, solver = 'liblinear'))\n",
        "      sel.fit(data_np, target_np)\n",
        "      sel_idx = sel.get_support()        \n",
        "\n",
        "    ##2) Get lists of selected and non-selected features (names and indexes) #######\n",
        "    temp=[]\n",
        "    temp_idx=[]\n",
        "    temp_del=[]\n",
        "    for i in range(len(data_np[0])):\n",
        "        if sel_idx[i]==1:                                                           #Selected Features get added to temp header\n",
        "            temp.append(header[i+feat_start])\n",
        "            temp_idx.append(i)\n",
        "        else:                                                                       #Indexes of non-selected features get added to delete array\n",
        "            temp_del.append(i)\n",
        "    print('Selected', temp)\n",
        "    print('Features (total/selected):', len(data_np[0]), len(temp))\n",
        "    print('\\n')\n",
        "            \n",
        "                \n",
        "    ##3) Filter selected columns from original dataset #########\n",
        "    header = header[0:feat_start]\n",
        "    for field in temp:\n",
        "        header.append(field)\n",
        "    data_np = np.delete(data_np, temp_del, axis=1)                                 #Deletes non-selected features by index)\n",
        "    \n",
        "    \n",
        "\n",
        "#############################################################################\n",
        "#\n",
        "# Train SciKit Models\n",
        "#\n",
        "##########################################\n",
        "\n",
        "print('--ML Model Output--', '\\n')\n",
        "\n",
        "#Test/Train split\n",
        "data_train, data_test, target_train, target_test = train_test_split(data_np, target_np, test_size=0.35)\n",
        "\n",
        "####Classifiers####\n",
        "\n",
        "                                                                           \n",
        " \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--FEATURE SELECTION ON-- \n",
            "\n",
            "Wrapper Select: \n",
            "Selected ['Revenue Growth', 'SG&A Expense', 'Income Tax Expense', 'EPS', 'EPS Diluted', 'Weighted Average Shs Out', 'Dividend per Share', 'EBITDA Margin', 'EBIT', 'Cash and cash equivalents', 'Total non-current assets', 'Total assets', 'Total non-current liabilities', 'Other Assets', 'Investment purchases and sales', 'Net Cash/Marketcap', 'priceBookValueRatio', 'priceEarningsRatio', 'priceToOperatingCashFlowsRatio', 'priceCashFlowRatio', 'priceSalesRatio', 'enterpriseValueMultiple', 'returnOnAssets', 'fixedAssetTurnover', 'currentRatio', 'cashFlowCoverageRatios', 'Net Income per Share', 'Tangible Book Value per Share', 'Market Cap', 'Price to Sales Ratio', 'PFCF ratio', 'Enterprise Value over EBITDA', 'EV to Operating cash flow', 'Current ratio', 'SG&A to Revenue', 'Return on Tangible Assets', 'Working Capital', 'Tangible Asset Value', 'Gross Profit Growth', 'Operating Income Growth', 'Weighted Average Shares Diluted Growth', 'Operating Cash Flow growth', '3Y Revenue Growth (per Share)', '3Y Operating CF Growth (per Share)', '5Y Net Income Growth (per Share)', '3Y Net Income Growth (per Share)', '5Y Dividend per Share Growth (per Share)', 'Inventory Growth', 'Asset Growth', 'SG&A Expenses Growth']\n",
            "Features (total/selected): 198 50\n",
            "\n",
            "\n",
            "--ML Model Output-- \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKj-Z9fylFLc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "eb63eeb9-d75c-4a95-bf04-e55ff03dd948"
      },
      "source": [
        "from sklearn.metrics import accuracy_score,roc_auc_score\n",
        "start_ts=time.time()\n",
        "clf=MLPClassifier(hidden_layer_sizes=(200),activation= \"logistic\",solver = \"lbfgs\",alpha = 0.0001, max_iter = 10000,random_state = rand_st)\n",
        "clf.fit(data_train.astype(np.float),target_train.astype(np.float))              \n",
        "y_pred = clf.predict(data_test.astype(np.float))\n",
        "#print(y_pred)\n",
        "#print(target_test.astype(np.float))\n",
        "print(accuracy_score(target_test.astype(np.float),y_pred))\n",
        "print(roc_auc_score(target_test.astype(np.float),y_pred))\n",
        "print(time.time()-start_ts)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.712606139777923\n",
            "0.6190187728421697\n",
            "31.711973905563354\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBhDX-e-tfdH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mlp=MLPClassifier(max_iter = 100,random_state = rand_st)\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5wwVBYHtfjh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parameter_space = {\n",
        "    'hidden_layer_sizes': [(50), (50,50), (100,),(100,100),(200,),(200,200),(250,)],\n",
        "    'activation': ['logistic','tanh', 'relu'],\n",
        "    'solver': ['sgd', 'adam'],\n",
        "    'alpha': [0.0001, 0.05],\n",
        "    'learning_rate': ['constant','adaptive'],\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7Txsc9jtfgF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "outputId": "acd1f890-5a75-49ef-87bd-89696245e8e3"
      },
      "source": [
        "clf = GridSearchCV(mlp, parameter_space, n_jobs=-1, cv=5)\n",
        "clf.fit(data_np.astype(np.float),target_np.astype(np.float))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=MLPClassifier(activation='relu', alpha=0.0001,\n",
              "                                     batch_size='auto', beta_1=0.9,\n",
              "                                     beta_2=0.999, early_stopping=False,\n",
              "                                     epsilon=1e-08, hidden_layer_sizes=(100,),\n",
              "                                     learning_rate='constant',\n",
              "                                     learning_rate_init=0.001, max_fun=15000,\n",
              "                                     max_iter=100, momentum=0.9,\n",
              "                                     n_iter_no_change=10,\n",
              "                                     nesterovs_momentum=True, power_t=0.5,\n",
              "                                     random_state...\n",
              "                                     validation_fraction=0.1, verbose=False,\n",
              "                                     warm_start=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'activation': ['logistic', 'tanh', 'relu'],\n",
              "                         'alpha': [0.0001, 0.05],\n",
              "                         'hidden_layer_sizes': [50, (50, 50), (100,),\n",
              "                                                (100, 100), (200,), (200, 200),\n",
              "                                                (250,)],\n",
              "                         'learning_rate': ['constant', 'adaptive'],\n",
              "                         'solver': ['sgd', 'adam']},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMLE20G-xDHA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9eea85bd-bf27-4f84-8a1e-18a753bdac7e"
      },
      "source": [
        "print('Best parameters found:\\n', clf.best_params_)\n",
        "\n",
        "# All results\n",
        "means = clf.cv_results_['mean_test_score']\n",
        "stds = clf.cv_results_['std_test_score']\n",
        "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
        "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best parameters found:\n",
            " {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': (200,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
            "0.713 (+/-0.032) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 50, 'learning_rate': 'constant', 'solver': 'sgd'}\n",
            "0.701 (+/-0.017) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 50, 'learning_rate': 'constant', 'solver': 'adam'}\n",
            "0.713 (+/-0.032) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 50, 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
            "0.701 (+/-0.017) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 50, 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
            "0.692 (+/-0.001) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
            "0.699 (+/-0.016) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
            "0.692 (+/-0.001) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
            "0.699 (+/-0.016) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
            "0.715 (+/-0.036) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
            "0.697 (+/-0.010) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
            "0.715 (+/-0.036) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
            "0.697 (+/-0.010) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
            "0.692 (+/-0.001) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': (100, 100), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
            "0.701 (+/-0.015) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': (100, 100), 'learning_rate': 'constant', 'solver': 'adam'}\n",
            "0.692 (+/-0.001) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': (100, 100), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
            "0.701 (+/-0.015) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': (100, 100), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
            "0.723 (+/-0.031) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': (200,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
            "0.700 (+/-0.012) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': (200,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
            "0.723 (+/-0.031) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': (200,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
            "0.700 (+/-0.012) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': (200,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
            "0.715 (+/-0.030) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': (200, 200), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
            "0.709 (+/-0.025) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': (200, 200), 'learning_rate': 'constant', 'solver': 'adam'}\n",
            "0.715 (+/-0.030) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': (200, 200), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
            "0.709 (+/-0.025) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': (200, 200), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
            "0.720 (+/-0.040) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': (250,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
            "0.705 (+/-0.021) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': (250,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
            "0.720 (+/-0.040) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': (250,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
            "0.705 (+/-0.021) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': (250,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
            "0.713 (+/-0.031) for {'activation': 'logistic', 'alpha': 0.05, 'hidden_layer_sizes': 50, 'learning_rate': 'constant', 'solver': 'sgd'}\n",
            "0.697 (+/-0.015) for {'activation': 'logistic', 'alpha': 0.05, 'hidden_layer_sizes': 50, 'learning_rate': 'constant', 'solver': 'adam'}\n",
            "0.713 (+/-0.031) for {'activation': 'logistic', 'alpha': 0.05, 'hidden_layer_sizes': 50, 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
            "0.697 (+/-0.015) for {'activation': 'logistic', 'alpha': 0.05, 'hidden_layer_sizes': 50, 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
            "0.692 (+/-0.001) for {'activation': 'logistic', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
            "0.694 (+/-0.005) for {'activation': 'logistic', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
            "0.692 (+/-0.001) for {'activation': 'logistic', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
            "0.694 (+/-0.005) for {'activation': 'logistic', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
            "0.715 (+/-0.035) for {'activation': 'logistic', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
            "0.702 (+/-0.011) for {'activation': 'logistic', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
            "0.715 (+/-0.035) for {'activation': 'logistic', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
            "0.702 (+/-0.011) for {'activation': 'logistic', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
            "0.692 (+/-0.001) for {'activation': 'logistic', 'alpha': 0.05, 'hidden_layer_sizes': (100, 100), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
            "0.703 (+/-0.018) for {'activation': 'logistic', 'alpha': 0.05, 'hidden_layer_sizes': (100, 100), 'learning_rate': 'constant', 'solver': 'adam'}\n",
            "0.692 (+/-0.001) for {'activation': 'logistic', 'alpha': 0.05, 'hidden_layer_sizes': (100, 100), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
            "0.703 (+/-0.018) for {'activation': 'logistic', 'alpha': 0.05, 'hidden_layer_sizes': (100, 100), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
            "0.708 (+/-0.010) for {'activation': 'logistic', 'alpha': 0.05, 'hidden_layer_sizes': (200,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
            "0.703 (+/-0.015) for {'activation': 'logistic', 'alpha': 0.05, 'hidden_layer_sizes': (200,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
            "0.712 (+/-0.018) for {'activation': 'logistic', 'alpha': 0.05, 'hidden_layer_sizes': (200,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
            "0.703 (+/-0.015) for {'activation': 'logistic', 'alpha': 0.05, 'hidden_layer_sizes': (200,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
            "0.694 (+/-0.009) for {'activation': 'logistic', 'alpha': 0.05, 'hidden_layer_sizes': (200, 200), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
            "0.704 (+/-0.016) for {'activation': 'logistic', 'alpha': 0.05, 'hidden_layer_sizes': (200, 200), 'learning_rate': 'constant', 'solver': 'adam'}\n",
            "0.694 (+/-0.009) for {'activation': 'logistic', 'alpha': 0.05, 'hidden_layer_sizes': (200, 200), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
            "0.704 (+/-0.016) for {'activation': 'logistic', 'alpha': 0.05, 'hidden_layer_sizes': (200, 200), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
            "0.721 (+/-0.041) for {'activation': 'logistic', 'alpha': 0.05, 'hidden_layer_sizes': (250,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
            "0.705 (+/-0.019) for {'activation': 'logistic', 'alpha': 0.05, 'hidden_layer_sizes': (250,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
            "0.721 (+/-0.041) for {'activation': 'logistic', 'alpha': 0.05, 'hidden_layer_sizes': (250,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
            "0.705 (+/-0.019) for {'activation': 'logistic', 'alpha': 0.05, 'hidden_layer_sizes': (250,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
            "0.712 (+/-0.022) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 50, 'learning_rate': 'constant', 'solver': 'sgd'}\n",
            "0.702 (+/-0.017) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 50, 'learning_rate': 'constant', 'solver': 'adam'}\n",
            "0.712 (+/-0.022) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 50, 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
            "0.702 (+/-0.017) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 50, 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
            "0.719 (+/-0.029) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
            "0.707 (+/-0.032) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
            "0.719 (+/-0.029) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
            "0.707 (+/-0.032) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
            "0.713 (+/-0.036) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
            "0.709 (+/-0.027) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
            "0.713 (+/-0.036) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
            "0.709 (+/-0.027) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
            "0.720 (+/-0.027) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100, 100), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
            "0.705 (+/-0.041) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100, 100), 'learning_rate': 'constant', 'solver': 'adam'}\n",
            "0.720 (+/-0.027) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100, 100), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
            "0.705 (+/-0.041) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100, 100), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
            "0.716 (+/-0.024) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (200,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
            "0.713 (+/-0.030) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (200,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
            "0.716 (+/-0.024) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (200,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
            "0.713 (+/-0.030) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (200,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
            "0.717 (+/-0.032) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (200, 200), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
            "0.711 (+/-0.032) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (200, 200), 'learning_rate': 'constant', 'solver': 'adam'}\n",
            "0.717 (+/-0.032) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (200, 200), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
            "0.711 (+/-0.032) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (200, 200), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
            "0.715 (+/-0.045) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (250,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
            "0.713 (+/-0.014) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (250,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
            "0.715 (+/-0.045) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (250,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
            "0.713 (+/-0.014) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (250,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
            "0.712 (+/-0.022) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': 50, 'learning_rate': 'constant', 'solver': 'sgd'}\n",
            "0.703 (+/-0.024) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': 50, 'learning_rate': 'constant', 'solver': 'adam'}\n",
            "0.712 (+/-0.022) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': 50, 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
            "0.703 (+/-0.024) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': 50, 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
            "0.719 (+/-0.028) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
            "0.708 (+/-0.029) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
            "0.719 (+/-0.028) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
            "0.708 (+/-0.029) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
            "0.713 (+/-0.037) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
            "0.704 (+/-0.018) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
            "0.713 (+/-0.037) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
            "0.704 (+/-0.018) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
            "0.720 (+/-0.027) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100, 100), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
            "0.706 (+/-0.030) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100, 100), 'learning_rate': 'constant', 'solver': 'adam'}\n",
            "0.720 (+/-0.027) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100, 100), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
            "0.706 (+/-0.030) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100, 100), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
            "0.716 (+/-0.025) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (200,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
            "0.706 (+/-0.023) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (200,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
            "0.716 (+/-0.025) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (200,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
            "0.706 (+/-0.023) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (200,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
            "0.718 (+/-0.032) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (200, 200), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
            "0.702 (+/-0.011) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (200, 200), 'learning_rate': 'constant', 'solver': 'adam'}\n",
            "0.718 (+/-0.032) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (200, 200), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
            "0.702 (+/-0.011) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (200, 200), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
            "0.715 (+/-0.045) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (250,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
            "0.705 (+/-0.023) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (250,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
            "0.715 (+/-0.045) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (250,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
            "0.705 (+/-0.023) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (250,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
            "0.308 (+/-0.001) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 50, 'learning_rate': 'constant', 'solver': 'sgd'}\n",
            "0.640 (+/-0.079) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 50, 'learning_rate': 'constant', 'solver': 'adam'}\n",
            "0.308 (+/-0.001) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 50, 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
            "0.640 (+/-0.079) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 50, 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
            "0.692 (+/-0.001) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
            "0.642 (+/-0.098) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
            "0.692 (+/-0.001) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
            "0.642 (+/-0.098) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
            "0.308 (+/-0.001) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
            "0.648 (+/-0.120) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
            "0.308 (+/-0.001) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
            "0.648 (+/-0.120) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
            "0.462 (+/-0.377) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100, 100), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
            "0.637 (+/-0.123) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100, 100), 'learning_rate': 'constant', 'solver': 'adam'}\n",
            "0.462 (+/-0.377) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100, 100), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
            "0.637 (+/-0.123) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100, 100), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
            "0.308 (+/-0.001) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (200,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
            "0.609 (+/-0.133) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (200,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
            "0.308 (+/-0.001) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (200,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
            "0.609 (+/-0.133) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (200,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
            "0.385 (+/-0.308) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (200, 200), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
            "0.659 (+/-0.070) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (200, 200), 'learning_rate': 'constant', 'solver': 'adam'}\n",
            "0.385 (+/-0.308) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (200, 200), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
            "0.659 (+/-0.070) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (200, 200), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
            "0.308 (+/-0.001) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (250,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
            "0.662 (+/-0.110) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (250,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
            "0.308 (+/-0.001) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (250,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
            "0.662 (+/-0.110) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (250,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
            "0.308 (+/-0.001) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': 50, 'learning_rate': 'constant', 'solver': 'sgd'}\n",
            "0.636 (+/-0.102) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': 50, 'learning_rate': 'constant', 'solver': 'adam'}\n",
            "0.308 (+/-0.001) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': 50, 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
            "0.636 (+/-0.102) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': 50, 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
            "0.692 (+/-0.001) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
            "0.657 (+/-0.060) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
            "0.692 (+/-0.001) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
            "0.657 (+/-0.060) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
            "0.308 (+/-0.001) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
            "0.680 (+/-0.109) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
            "0.308 (+/-0.001) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
            "0.680 (+/-0.109) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
            "0.462 (+/-0.377) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100, 100), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
            "0.651 (+/-0.092) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100, 100), 'learning_rate': 'constant', 'solver': 'adam'}\n",
            "0.462 (+/-0.377) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100, 100), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
            "0.651 (+/-0.092) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100, 100), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
            "0.308 (+/-0.001) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (200,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
            "0.647 (+/-0.140) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (200,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
            "0.308 (+/-0.001) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (200,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
            "0.647 (+/-0.140) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (200,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
            "0.385 (+/-0.308) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (200, 200), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
            "0.670 (+/-0.057) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (200, 200), 'learning_rate': 'constant', 'solver': 'adam'}\n",
            "0.385 (+/-0.308) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (200, 200), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
            "0.670 (+/-0.057) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (200, 200), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
            "0.308 (+/-0.001) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (250,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
            "0.681 (+/-0.088) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (250,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
            "0.308 (+/-0.001) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (250,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
            "0.681 (+/-0.088) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (250,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}